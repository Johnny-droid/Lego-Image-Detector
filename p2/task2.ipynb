{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VC Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mnist import MNIST\n",
    "import warnings\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# ======================== Suppress Warnings ========================\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mount Google Drive\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(num, imgLoadSizeRatio = 1, dataDir = 'imgs', standardSize = -1):\n",
    "    img = cv2.imread(os.path.join(dataDir, f'{num}.jpg'))\n",
    "    if standardSize > 0:\n",
    "        img = cv2.resize(img, (standardSize, standardSize))\n",
    "    elif imgLoadSizeRatio != 1:\n",
    "        img = cv2.resize(img, (0, 0), fx = imgLoadSizeRatio, fy = imgLoadSizeRatio)\n",
    "    return img\n",
    "\n",
    "def render(image):\n",
    "    if image.dtype == np.float64:\n",
    "        image = cv2.convertScaleAbs(image)\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3: # BGR or RGB\n",
    "        if np.array_equal(image[:, :, 0], image[:, :, 2]):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img_bytes = cv2.imencode('.png', image)[1].tobytes()\n",
    "    display(Image(data=img_bytes))\n",
    "\n",
    "df_lego_sets = pd.read_csv(\"lego_sets.csv\")\n",
    "def getActualPieceCount(imgID):\n",
    "    global df_lego_sets\n",
    "    piece_count = df_lego_sets.loc[df_lego_sets['id'] == imgID, 'piece_count'].values[0]\n",
    "    return piece_count \n",
    "\n",
    "def makeGuess(image_id, num_guess):\n",
    "    piece_count = getActualPieceCount(image_id)\n",
    "    num_legos_error = abs(num_guess - piece_count)\n",
    "    \n",
    "    if(num_legos_error > 0):\n",
    "        print(f\"Error in Lego Count - Guessed: {num_guess} | Actual: {piece_count} legos\")\n",
    "    else :\n",
    "        print(f\"Perfect ({num_guess}) Guess!\")\n",
    "        \n",
    "    return piece_count, num_legos_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672\n",
      "1168\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "\n",
    "for i in range(0, 5840):\n",
    "    img = loadImage(i)\n",
    "    count = getActualPieceCount(i)\n",
    "    imgs.append((img, count))\n",
    "\n",
    "    # apply multiple transformations to the image to upsample the dataset\n",
    "    \n",
    "    \"\"\" # Rotation\n",
    "    rotated_image_90 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    imgs.append((rotated_image_90, count))\n",
    "    \n",
    "    rotated_image_180 = cv2.rotate(img, cv2.ROTATE_180)\n",
    "    imgs.append((rotated_image_180, count))\n",
    "    \n",
    "    rotated_image_270 = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    imgs.append((rotated_image_270, count))\n",
    "    \n",
    "    # Flipping\n",
    "    flipped_image = cv2.flip(img, flipCode=1)\n",
    "    imgs.append((flipped_image, count))\n",
    "    \n",
    "    flipped_image = cv2.flip(img, flipCode=0)\n",
    "    imgs.append((flipped_image, count))\n",
    "    \n",
    "    # Rotation + Flipping\n",
    "    rotated_flipped_image = cv2.flip(rotated_image_90, flipCode=1)\n",
    "    imgs.append((rotated_flipped_image, count)) \"\"\"\n",
    "\n",
    "# suffle the images\n",
    "np.random.shuffle(imgs)    \n",
    "    \n",
    "# pick the first 80% of the images for training\n",
    "train_imgs = imgs[:int(len(imgs)*0.8)]\n",
    "\n",
    "# pick the remaining 20% of the images for validation\n",
    "val_imgs = imgs[int(len(imgs)*0.8):]\n",
    "\n",
    "print(len(train_imgs))\n",
    "print(len(val_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      image = self.images[idx]\n",
    "\n",
    "      # Apply transformations to the image\n",
    "      if self.transform:\n",
    "        image = self.transform(image)\n",
    "\n",
    "      label = int(self.labels[idx])\n",
    "      return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "19\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "train_images = [img[0] for img in train_imgs]\n",
    "train_labels = [img[1] for img in train_imgs]\n",
    "val_images = [img[0] for img in val_imgs]\n",
    "val_labels = [img[1] for img in val_imgs]\n",
    "\n",
    "batch_size = 64 # how many images are processed at a time\n",
    "num_workers = 2 # how many processes are used to load the data\n",
    "\n",
    "# Define transformations\n",
    "data_aug = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Create dataset objects\n",
    "training_data = CustomDataset(train_images, train_labels, transform=data_aug)\n",
    "validation_data = CustomDataset(val_images, val_labels, transform=data_aug)\n",
    "\n",
    "# Define data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Show one image\n",
    "# plt.imshow(training_data[0][0][0,:,:], cmap='gray')\n",
    "\n",
    "print(len(train_dataloader))\n",
    "print(len(validation_dataloader))\n",
    "\n",
    "# Get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalNeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Dropout(p=0.25, inplace=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Dropout(p=0.25, inplace=False)\n",
      "    (12): Flatten(start_dim=1, end_dim=-1)\n",
      "    (13): Linear(in_features=331776, out_features=512, bias=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Linear(in_features=512, out_features=33, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        self.pool_size = 2\n",
    "        self.nb_filters = 32\n",
    "        self.kernel_size = 3\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, self.nb_filters, self.kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.nb_filters, self.nb_filters, self.kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(self.pool_size),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(self.nb_filters, self.nb_filters * 2, self.kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.nb_filters * 2, self.nb_filters * 2, self.kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(self.pool_size),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(331776, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 33)  # we have 33 classes to guess\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits\n",
    "\n",
    "model = ConvolutionalNeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to save the models\n",
    "try:\n",
    "    folder_name = \"models\"\n",
    "    os.mkdir(folder_name)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_iter(dataloader, model, loss_fn, optimizer=None, is_train=True):\n",
    "    if is_train:\n",
    "      assert optimizer is not None, \"When training, please provide an optimizer.\"\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    if num_batches == 0:\n",
    "      print(\"No data in the dataloader\")\n",
    "      return 0.0, 0.0\n",
    "\n",
    "    if is_train:\n",
    "      model.train()\n",
    "    else:\n",
    "      model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "      for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          # Obtain prediction\n",
    "          pred = model(X)\n",
    "          \n",
    "          # Obtain loss value\n",
    "          loss = loss_fn(pred, y)\n",
    "\n",
    "          if is_train:\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "          # Save training metrics\n",
    "          total_loss += loss.item() # IMPORTANT: call .item() to obtain the value of the loss WITHOUT the computational graph attached\n",
    "\n",
    "          # Calculate final prediction\n",
    "          probs = F.softmax(pred, dim=1)\n",
    "          final_pred = torch.argmax(probs, dim=1)\n",
    "          preds.extend(final_pred.cpu().numpy())\n",
    "          labels.extend(y.cpu().numpy())\n",
    "\n",
    "    return total_loss / num_batches, accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, num_epochs, train_dataloader, validation_dataloader, loss_fn, optimizer):\n",
    "  \n",
    "  train_history = {'loss': [], 'accuracy': []}\n",
    "  val_history = {'loss': [], 'accuracy': []}\n",
    "  \n",
    "  best_val_loss = np.inf\n",
    "  \n",
    "  print(\"Start training...\")\n",
    "  \n",
    "  for t in range(num_epochs):\n",
    "    \n",
    "      print(f\"\\nEpoch {t+1}\")\n",
    "      \n",
    "      train_loss, train_acc = epoch_iter(train_dataloader, model, loss_fn, optimizer)\n",
    "      print(f\"Train loss: {train_loss:.3f} \\t Train acc: {train_acc:.3f}\")\n",
    "      \n",
    "      if(train_acc > 0):\n",
    "        val_loss, val_acc = epoch_iter(validation_dataloader, model, loss_fn, is_train=False)\n",
    "      else :\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        \n",
    "      print(f\"Val loss: {val_loss:.3f} \\t Val acc: {val_acc:.3f}\")\n",
    "\n",
    "      # save model when val loss improves\n",
    "      if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
    "        torch.save(save_dict, \"models/\" + model_name + '_best_model.pth')\n",
    "\n",
    "      # save latest model\n",
    "      save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
    "      torch.save(save_dict, \"models/\" + model_name + '_latest_model.pth')\n",
    "\n",
    "      # save training history for plotting purposes\n",
    "      train_history[\"loss\"].append(train_loss)\n",
    "      train_history[\"accuracy\"].append(train_acc)\n",
    "\n",
    "      val_history[\"loss\"].append(val_loss)\n",
    "      val_history[\"accuracy\"].append(val_acc)\n",
    "      \n",
    "  print(\"Finished\")\n",
    "  return train_history, val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingHistory(train_history, val_history):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(train_history['loss'], label='train')\n",
    "    plt.plot(val_history['loss'], label='val')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(train_history['accuracy'], label='train')\n",
    "    plt.plot(val_history['accuracy'], label='val')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 56/73 [22:59<03:55, 13.82s/it]  "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model_name = 'custom_CNN'\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_custom = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "custom_train_history, custom_val_history = train(model, model_name, num_epochs, train_dataloader, validation_dataloader, loss_fn, optimizer_custom)\n",
    "\n",
    "plotTrainingHistory(custom_train_history, custom_val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = ConvolutionalNeuralNetwork().to(device)\n",
    "checkpoint = torch.load(\"models/\" + model_name + '_best_model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "# Test model\n",
    "# test_loss, test_acc = epoch_iter(test_dataloader, model, loss_fn, is_train=False)\n",
    "# print(f\"\\nTest Loss: {test_loss:.3f} \\nTest Accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showErrors(model, dataloader, num_examples=20):    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    for ind, (X, y) in enumerate(dataloader):\n",
    "      if ind >= 20: break\n",
    "      X, y = X.to(device), y.to(device)    \n",
    "      pred = model(X)\n",
    "      probs = F.softmax(pred, dim=1)\n",
    "      final_pred = torch.argmax(probs, dim=1)\n",
    "\n",
    "      plt.subplot(10, 10, ind + 1)\n",
    "      plt.axis(\"off\")\n",
    "      plt.text(0, -1, y[0].item(), fontsize=14, color='green') # correct\n",
    "      plt.text(8, -1, final_pred[0].item(), fontsize=14, color='red')  # predicted\n",
    "      plt.imshow(X[0][0,:,:].cpu(), cmap='gray')\n",
    "      \n",
    "    plt.show()\n",
    "    \n",
    "# showErrors(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Click here to check the pre-trained models that are available on torchvision.](https://pytorch.org/vision/0.9/models.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = models.vgg16(pretrained=True)\n",
    "vgg.to(device)\n",
    "\n",
    "# set out_features of the last layer to 33\n",
    "vgg.classifier[6] = nn.Linear(4096, 33)\n",
    "\n",
    "print(vgg)\n",
    "\n",
    "# Train network for 10 epochs\n",
    "num_epochs = 10\n",
    "model_name = 'vgg16'\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_vgg = torch.optim.SGD(vgg.parameters(), lr=0.01)\n",
    "\n",
    "vgg_train_history, vgg_val_history = train(vgg, model_name, num_epochs, train_dataloader, validation_dataloader, loss_fn, optimizer_vgg)\n",
    "\n",
    "plotTrainingHistory(vgg_train_history, vgg_val_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
