{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.datasets import CocoDetection\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import Compose, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "class LegoDataset(CocoDetection):\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = super().__getitem__(idx)\n",
    "        img = F.to_tensor(img)\n",
    "        \n",
    "        # Convert target to desired format\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in target:\n",
    "            xmin, ymin, width, height = obj['bbox']\n",
    "            boxes.append([xmin, ymin, xmin + width, ymin + height])\n",
    "            labels.append(obj['category_id'])\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "dataset = LegoDataset('data/imgs', 'faster_r_cnn.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    # Load a pre-trained model for classification and return only the features\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "num_classes = 2 # 1 class (lego) + background\n",
    "model = get_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 finished.\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "\n",
    "# Move model to the correct device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Training function\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
    "    print(f\"Epoch {epoch} finished.\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'lego_fasterrcnn.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[134.4769, 119.0376, 146.9966, 129.0684],\n",
      "        [105.3467, 114.2255, 116.8834, 121.9928],\n",
      "        [105.5964, 196.2340, 125.1398, 209.3532],\n",
      "        [ 75.2217, 187.8367,  89.4976, 210.7990],\n",
      "        [125.0777, 140.9013, 148.8088, 160.8630],\n",
      "        [152.5215, 131.8268, 165.5538, 142.7635],\n",
      "        [ 94.1864,  15.4764, 107.1057,  31.8908],\n",
      "        [110.8575,  92.5573, 131.7252, 102.0790],\n",
      "        [108.3662, 155.0198, 125.0086, 167.4651],\n",
      "        [129.9701,  14.4197, 140.9499,  22.2021],\n",
      "        [151.6155,  72.7795, 169.2446,  90.5884],\n",
      "        [145.1336,  51.8578, 156.2168,  62.7207],\n",
      "        [ 75.4288, 150.8042,  99.8903, 169.6171],\n",
      "        [144.3372, 103.5472, 154.2623, 113.0652],\n",
      "        [ 79.7614,  30.8931,  88.3207,  39.4577],\n",
      "        [ 84.5133,  86.0216,  98.9886,  97.4525],\n",
      "        [107.8348,  49.0068, 126.9868,  65.1537],\n",
      "        [123.0213, 167.2093, 132.4824, 176.1359],\n",
      "        [167.1742, 166.3310, 188.6536, 193.1087],\n",
      "        [ 78.1562,  69.6970,  98.3133,  81.0412],\n",
      "        [ 96.7308, 168.6303, 120.0053, 178.9833],\n",
      "        [ 85.9326,  51.4232, 107.3079,  68.5599],\n",
      "        [134.7722, 188.3576, 160.4491, 224.0000],\n",
      "        [118.0887,  71.7810, 129.0397,  80.8268],\n",
      "        [ 63.4691, 115.3616,  85.2877, 158.8382],\n",
      "        [124.9190,  57.3399, 135.5085,  66.6116],\n",
      "        [132.5854,  42.8177, 146.0754,  58.7401],\n",
      "        [153.5472,  87.0689, 173.1625,  97.9425],\n",
      "        [102.4638,  30.9391, 113.0850,  40.6975],\n",
      "        [151.8554,  78.1930, 172.4258, 100.1704],\n",
      "        [ 70.9694,  70.8291,  84.4596,  80.4155],\n",
      "        [ 94.3829,  49.3140, 134.6520,  68.3854],\n",
      "        [ 65.7456, 108.2188,  92.5599, 193.6248]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.9949, 0.9934, 0.9933, 0.9920, 0.9912, 0.9906, 0.9904, 0.9901, 0.9893,\n",
      "        0.9884, 0.9882, 0.9881, 0.9878, 0.9846, 0.9832, 0.9794, 0.9769, 0.9766,\n",
      "        0.9688, 0.9688, 0.9631, 0.9620, 0.9613, 0.9590, 0.9574, 0.9512, 0.9428,\n",
      "        0.9209, 0.8666, 0.3411, 0.3147, 0.2926, 0.0832])}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the trained model\n",
    "model.load_state_dict(torch.load('lego_fasterrcnn.pth'))\n",
    "model.eval()\n",
    "\n",
    "def predict(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = F.to_tensor(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image_tensor)\n",
    "    return prediction\n",
    "\n",
    "# Make a prediction\n",
    "image_path = 'data/imgs/30_1.jpg'\n",
    "prediction = predict(image_path)\n",
    "print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
