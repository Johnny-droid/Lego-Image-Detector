{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VC Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mnist import MNIST\n",
    "import warnings\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# ======================== Suppress Warnings ========================\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(num):\n",
    "    imgLoadSizeRatio = 0.1\n",
    "    dataDir = 'imgs'\n",
    "\n",
    "    img = cv2.imread(os.path.join(dataDir, f'{num}.jpg'))\n",
    "    img = cv2.resize(img, (0, 0), fx = imgLoadSizeRatio, fy = imgLoadSizeRatio)\n",
    "    return img\n",
    "\n",
    "def render(image):\n",
    "    images = [image]\n",
    "    for i in range(len(images)):\n",
    "        if images[i].dtype == np.float64:\n",
    "            image = cv2.convertScaleAbs(images[i])\n",
    "        else:\n",
    "            image = images[i]\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3: # BGR or RGB\n",
    "            if np.array_equal(image[:, :, 0], image[:, :, 2]):\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img_bytes = cv2.imencode('.png', image)[1].tobytes()\n",
    "        display(Image(data=img_bytes))\n",
    "\n",
    "def getActualPieceCount(imgID):\n",
    "    df = pd.read_csv(\"lego_sets.csv\")\n",
    "    piece_count = df.loc[df['id'] == imgID, 'piece_count'].values[0]\n",
    "    return piece_count \n",
    "\n",
    "def makeGuess(image_id, num_guess):\n",
    "    piece_count = getActualPieceCount(image_id)\n",
    "    num_legos_error = abs(num_guess - piece_count)\n",
    "    \n",
    "    if(num_legos_error > 0):\n",
    "        print(f\"Error in Lego Count - Guessed: {num_guess} | Actual: {piece_count} legos\")\n",
    "    else :\n",
    "        print(f\"Perfect ({num_guess}) Guess!\")\n",
    "        \n",
    "    return piece_count, num_legos_error\n",
    "    \n",
    "def singleImagePredict(image_id):\n",
    "\n",
    "    og_img = loadImage(image_id)\n",
    "    \n",
    "    print(\"Original Image\")\n",
    "    render(og_img)\n",
    "\n",
    "    # TODO: EXECUTE MODEL\n",
    "    num_guess = 0       \n",
    "        \n",
    "    return num_guess\n",
    "\n",
    "def evaluate():\n",
    "    \n",
    "    total_lego_error = 0\n",
    "    total_lego = 0\n",
    "    error_count_ids = []\n",
    "\n",
    "    for i in range(0, 50):\n",
    "        print(f\"\\n======================== Image {i} ========================\\n\")\n",
    "        num_legos_guess = singleImagePredict(i)\n",
    "        piece_count, num_legos_error = makeGuess(i, num_legos_guess)\n",
    "        \n",
    "        if(num_legos_error > 0):\n",
    "            error_count_ids.append(i)\n",
    "\n",
    "        total_lego_error += num_legos_error\n",
    "        total_lego += piece_count\n",
    "    \n",
    "    error_count_ids = set(error_count_ids)\n",
    "    \n",
    "    print(f\"\\n\\n======================== TOTAL RESULTS ========================\")   \n",
    "    print(f\"Total Lego Error: {total_lego_error} | {total_lego}\")\n",
    "    print(\"Num of images with count errors: \" + str(len(error_count_ids)))\n",
    "    print(\"Error images: \" + str(error_count_ids))\n",
    "    print(\"===============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "for i in range(0, 50):\n",
    "    img = loadImage(i)\n",
    "    imgs.append(img)\n",
    "    \n",
    "# pick the first 80% of the images for training\n",
    "train_imgs = imgs[:int(len(imgs)*0.8)]\n",
    "\n",
    "# pick the remaining 20% of the images for validation\n",
    "val_imgs = imgs[int(len(imgs)*0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Define transformations\n",
    "data_aug = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "batch_size = 64 # how many images are processed at a time\n",
    "num_workers = 2 # how many processes are used to load the data\n",
    "\n",
    "# Define data loaders\n",
    "train_dataloader = DataLoader(train_imgs, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "validation_dataloader = DataLoader(val_imgs, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "test_dataloader = DataLoader(val_imgs, batch_size=1, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "\n",
    "# Get cpu or gpu device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalNeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Dropout(p=0.25, inplace=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=6272, out_features=64, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Dropout(p=0.5, inplace=False)\n",
      "    (10): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        self.pool_size = 2\n",
    "        self.nb_filters = 32\n",
    "        self.kernel_size = 3\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, self.nb_filters, self.kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.nb_filters, self.nb_filters, self.kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(self.pool_size),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(6272, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 10), # we have 10 classes to guess\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits\n",
    "\n",
    "model = ConvolutionalNeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def epoch_iter(dataloader, model, loss_fn, optimizer=None, is_train=True):\n",
    "    if is_train:\n",
    "      assert optimizer is not None, \"When training, please provide an optimizer.\"\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    if num_batches == 0:\n",
    "      print(\"No data in the dataloader\")\n",
    "      return 0.0, 0.0\n",
    "\n",
    "    if is_train:\n",
    "      model.train()\n",
    "    else:\n",
    "      model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "      for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          # Obtain prediction\n",
    "          pred = model(X)\n",
    "          \n",
    "          # Obtain loss value\n",
    "          loss = loss_fn(pred, y)\n",
    "\n",
    "          if is_train:\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "          # Save training metrics\n",
    "          total_loss += loss.item() # IMPORTANT: call .item() to obtain the value of the loss WITHOUT the computational graph attached\n",
    "\n",
    "          # Calculate final prediction\n",
    "          probs = F.softmax(pred, dim=1)\n",
    "          final_pred = torch.argmax(probs, dim=1)\n",
    "          preds.extend(final_pred.cpu().numpy())\n",
    "          labels.extend(y.cpu().numpy())\n",
    "\n",
    "    return total_loss / num_batches, accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name, num_epochs, train_dataloader, validation_dataloader, loss_fn, optimizer):\n",
    "  train_history = {'loss': [], 'accuracy': []}\n",
    "  val_history = {'loss': [], 'accuracy': []}\n",
    "  best_val_loss = np.inf\n",
    "  print(\"Start training...\")\n",
    "  for t in range(num_epochs):\n",
    "      print(f\"\\nEpoch {t+1}\")\n",
    "      train_loss, train_acc = epoch_iter(train_dataloader, model, loss_fn, optimizer)\n",
    "      print(f\"Train loss: {train_loss:.3f} \\t Train acc: {train_acc:.3f}\")\n",
    "      if(train_acc > 0):\n",
    "        val_loss, val_acc = epoch_iter(validation_dataloader, model, loss_fn, is_train=False)\n",
    "      else :\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "      print(f\"Val loss: {val_loss:.3f} \\t Val acc: {val_acc:.3f}\")\n",
    "\n",
    "      # save model when val loss improves\n",
    "      if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
    "        torch.save(save_dict, model_name + '_best_model.pth')\n",
    "\n",
    "      # save latest model\n",
    "      save_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': t}\n",
    "      torch.save(save_dict, model_name + '_latest_model.pth')\n",
    "\n",
    "      # save training history for plotting purposes\n",
    "      train_history[\"loss\"].append(train_loss)\n",
    "      train_history[\"accuracy\"].append(train_acc)\n",
    "\n",
    "      val_history[\"loss\"].append(val_loss)\n",
    "      val_history[\"accuracy\"].append(val_acc)\n",
    "      \n",
    "  print(\"Finished\")\n",
    "  return train_history, val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingHistory(train_history, val_history):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(train_history['loss'], label='train')\n",
    "    plt.plot(val_history['loss'], label='val')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(train_history['accuracy'], label='train')\n",
    "    plt.plot(val_history['accuracy'], label='val')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      "Epoch 1\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 2\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 3\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 4\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 5\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 6\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 7\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 8\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 9\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 10\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "Finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train network for 10 epochs\n",
    "num_epochs = 10\n",
    "model_name = 'custom_CNN'\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_custom = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "custom_train_history, custom_val_history = train(model, model_name, num_epochs, train_dataloader, validation_dataloader, loss_fn, optimizer_custom)\n",
    "\n",
    "plotTrainingHistory(custom_train_history, custom_val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = ConvolutionalNeuralNetwork().to(device)\n",
    "checkpoint = torch.load(model_name + '_best_model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "# Test model\n",
    "# test_loss, test_acc = epoch_iter(test_dataloader, model, loss_fn, is_train=False)\n",
    "# print(f\"\\nTest Loss: {test_loss:.3f} \\nTest Accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showErrors(model, dataloader, num_examples=20):    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    for ind, (X, y) in enumerate(dataloader):\n",
    "      if ind >= 20: break\n",
    "      X, y = X.to(device), y.to(device)    \n",
    "      pred = model(X)\n",
    "      probs = F.softmax(pred, dim=1)\n",
    "      final_pred = torch.argmax(probs, dim=1)\n",
    "\n",
    "      plt.subplot(10, 10, ind + 1)\n",
    "      plt.axis(\"off\")\n",
    "      plt.text(0, -1, y[0].item(), fontsize=14, color='green') # correct\n",
    "      plt.text(8, -1, final_pred[0].item(), fontsize=14, color='red')  # predicted\n",
    "      plt.imshow(X[0][0,:,:].cpu(), cmap='gray')\n",
    "      \n",
    "    plt.show()\n",
    "    \n",
    "# showErrors(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Click here to check the pre-trained models that are available on torchvision.](https://pytorch.org/vision/0.9/models.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load VGG model from torchvision (with pretrained=True)\n",
    "vgg = models.vgg16(pretrained=True)\n",
    "\n",
    "# Change the number of neurons in the last layer to the number of classes of the CIFAR10 dataset\n",
    "vgg.classifier[6] = nn.Linear(4096, 10)\n",
    "\n",
    "vgg.to(device)\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      "Epoch 1\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 2\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 3\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 4\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 5\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 6\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 7\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 8\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 9\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "\n",
      "Epoch 10\n",
      "No data in the dataloader\n",
      "Train loss: 0.000 \t Train acc: 0.000\n",
      "Val loss: 0.000 \t Val acc: 0.000\n",
      "Finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train network for 10 epochs\n",
    "num_epochs = 10\n",
    "model_name = 'vgg16'\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_vgg = torch.optim.SGD(vgg.parameters(), lr=1e-3)\n",
    "\n",
    "vgg_train_history, vgg_val_history = train(vgg, model_name, num_epochs, train_dataloader, validation_dataloader, loss_fn, optimizer_vgg)\n",
    "\n",
    "plotTrainingHistory(vgg_train_history, vgg_val_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
