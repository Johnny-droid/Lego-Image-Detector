{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.datasets import CocoDetection\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from IPython.display import display, Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(image):\n",
    "    if image.dtype == np.float64:\n",
    "        image = cv2.convertScaleAbs(image)\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3: # BGR or RGB\n",
    "        if np.array_equal(image[:, :, 0], image[:, :, 2]):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img_bytes = cv2.imencode('.jpg', image)[1].tobytes()\n",
    "    display(Image(data=img_bytes))\n",
    "    \n",
    "def loadImage(path):\n",
    "    img = cv2.imread(os.path.join('', f'{path}'))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.16s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "class LegoDataset(CocoDetection):\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = super().__getitem__(idx)\n",
    "        img = F.to_tensor(img)\n",
    "        \n",
    "        # Convert target to desired format\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in target:\n",
    "            xmin, ymin, width, height = obj['bbox']\n",
    "            boxes.append([xmin, ymin, xmin + width, ymin + height])\n",
    "            labels.append(obj['category_id'])\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "dataset = LegoDataset('data/imgs', 'faster_r_cnn.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/m/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "def get_model(num_classes):\n",
    "    # Load a pre-trained model for classification and return only the features\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "num_classes = 2 # 1 class (lego) + background\n",
    "model = get_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 finished.\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "\n",
    "# Move model to the correct device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Training function\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
    "    print(f\"Epoch {epoch} finished.\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'lego_fasterrcnn.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model.load_state_dict(torch.load('lego_fasterrcnn.pth'))\n",
    "model.eval()\n",
    "\n",
    "def predict(image_path):\n",
    "    image = loadImage(image_path)\n",
    "    image_tensor = F.to_tensor(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image_tensor)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "image_path = '../data/imgs/1_1.jpg'\n",
    "prediction = predict(image_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([116.6627,  88.1037, 154.0497, 128.7520])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = loadImage(image_path)\n",
    "\n",
    "# Draw boxes on the image\n",
    "boxes = prediction['boxes']\n",
    "scores = prediction['scores']\n",
    "\n",
    "for box, score in zip(boxes, scores):\n",
    "    print(box)\n",
    "    box = [int(i) for i in box.tolist()]\n",
    "    image = cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)\n",
    "    \n",
    "render(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
